from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import xgboost as xgb
import math
import re
import os
from sklearn.preprocessing import MultiLabelBinarizer

# ---------------- CONFIG ----------------
stream_csv_path = "./realtime_scraping/out/traffy_reports_stream.csv"
output_csv_path = "./realtime_scraping/out/traffy_reports_latest.csv"
model_path = "./model.json"

# ---------------- DISTRICT COORDINATES ----------------
district_office_location = {
    "‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£": (13.764928875843303, 100.49876110201305),
    "‡∏î‡∏∏‡∏™‡∏¥‡∏ï": (13.777137865519553, 100.52060070041834),
    "‡∏´‡∏ô‡∏≠‡∏á‡∏à‡∏≠‡∏Å": (13.855559348924416, 100.86250879511516),
    "‡∏ö‡∏≤‡∏á‡∏£‡∏±‡∏Å": (13.730665492976234, 100.52348632968096),
    "‡∏ö‡∏≤‡∏á‡πÄ‡∏Ç‡∏ô": (13.873390441022337, 100.59607817647071),
    "‡∏ö‡∏≤‡∏á‡∏Å‡∏∞‡∏õ‡∏¥": (13.765784458084667, 100.64746466418079),
    "‡∏õ‡∏ó‡∏∏‡∏°‡∏ß‡∏±‡∏ô": (13.744775870775214, 100.5221679872862),
    "‡∏õ‡πâ‡∏≠‡∏°‡∏õ‡∏£‡∏≤‡∏ö‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡πà‡∏≤‡∏¢": (13.758131278192316, 100.51305765683877),
    "‡∏û‡∏£‡∏∞‡πÇ‡∏Ç‡∏ô‡∏á": (13.70245388463174, 100.60201995932142),
    "‡∏°‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ": (13.813520000292137, 100.73129315090954),
    "‡∏•‡∏≤‡∏î‡∏Å‡∏£‡∏∞‡∏ö‡∏±‡∏á": (13.722351512642533, 100.75973821018188),
    "‡∏¢‡∏≤‡∏ô‡∏ô‡∏≤‡∏ß‡∏≤": (13.696255941440228, 100.54241169046436),
    "‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡∏ß‡∏á‡∏®‡πå": (13.731558621128627, 100.51390480776924),
    "‡∏û‡∏ç‡∏≤‡πÑ‡∏ó": (13.779841550638082, 100.54260649347228),
    "‡∏ò‡∏ô‡∏ö‡∏∏‡∏£‡∏µ": (13.724893996581253, 100.48586473528377),
    "‡∏ö‡∏≤‡∏á‡∏Å‡∏≠‡∏Å‡πÉ‡∏´‡∏ç‡πà": (13.72329283806953, 100.47632489414428),
    "‡∏´‡πâ‡∏ß‡∏¢‡∏Ç‡∏ß‡∏≤‡∏á": (13.776625058927335, 100.57937113544617),
    "‡∏Ñ‡∏•‡∏≠‡∏á‡∏™‡∏≤‡∏ô": (13.73053678969251, 100.50925221037632),
    "‡∏ï‡∏•‡∏¥‡πà‡∏á‡∏ä‡∏±‡∏ô": (13.776756576321823, 100.45648886139783),
    "‡∏ö‡∏≤‡∏á‡∏Å‡∏≠‡∏Å‡∏ô‡πâ‡∏≠‡∏¢": (13.770793361442882, 100.46804511658367),
    "‡∏ö‡∏≤‡∏á‡∏Ç‡∏∏‡∏ô‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô": (13.66075667619237, 100.4353903434257),
    "‡∏†‡∏≤‡∏©‡∏µ‡πÄ‡∏à‡∏£‡∏¥‡∏ç": (13.714805942839531, 100.43692254219468),
    "‡∏´‡∏ô‡∏≠‡∏á‡πÅ‡∏Ç‡∏°": (13.70541823094582, 100.34920888486124),
    "‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ö‡∏π‡∏£‡∏ì‡∏∞": (13.681850188598025, 100.5057611421854),
    "‡∏ö‡∏≤‡∏á‡∏û‡∏•‡∏±‡∏î": (13.793908773714579, 100.5050753627661),
    "‡∏î‡∏¥‡∏ô‡πÅ‡∏î‡∏á": (13.769825608522584, 100.55312850612616),
    "‡∏ö‡∏∂‡∏á‡∏Å‡∏∏‡πà‡∏°": (13.785556222552538, 100.66950529166158),
    "‡∏™‡∏≤‡∏ó‡∏£": (13.707986680426469, 100.52630474790409),
    "‡∏ö‡∏≤‡∏á‡∏ã‡∏∑‡πà‡∏≠": (13.809566088625214, 100.53722971209244),
    "‡∏à‡∏ï‡∏∏‡∏à‡∏±‡∏Å‡∏£": (13.828652086836676, 100.55997360729539),
    "‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≠‡πÅ‡∏´‡∏•‡∏°": (13.692952387248127, 100.50253057855271),
    "‡∏õ‡∏£‡∏∞‡πÄ‡∏ß‡∏®": (13.717246339846502, 100.69467236477642),
    "‡∏Ñ‡∏•‡∏≠‡∏á‡πÄ‡∏ï‡∏¢": (13.708220611673642, 100.58369685106754),
    "‡∏™‡∏ß‡∏ô‡∏´‡∏•‡∏ß‡∏á": (13.730170291834963, 100.651251012509),
    "‡∏à‡∏≠‡∏°‡∏ó‡∏≠‡∏á": (13.677562701369771, 100.4841897677573),
    "‡∏î‡∏≠‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á": (13.90995378737537, 100.59470365026687),
    "‡∏£‡∏≤‡∏ä‡πÄ‡∏ó‡∏ß‡∏µ": (13.759173863154476, 100.5341275810791),
    "‡∏•‡∏≤‡∏î‡∏û‡∏£‡πâ‡∏≤‡∏ß": (13.803577537305433, 100.60752329243601),
    "‡∏ß‡∏±‡∏í‡∏ô‡∏≤": (13.742408399794114, 100.5859127880872),
    "‡∏ö‡∏≤‡∏á‡πÅ‡∏Ñ": (13.696203940032568, 100.4091302644525),
    "‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏µ‡πà": (13.887444345533599, 100.57891693181126),
    "‡∏™‡∏≤‡∏¢‡πÑ‡∏´‡∏°": (13.895108760246032, 100.66051827468355),
    "‡∏Ñ‡∏±‡∏ô‡∏ô‡∏≤‡∏¢‡∏≤‡∏ß": (13.799302669559399, 100.68267045862126),
    "‡∏™‡∏∞‡∏û‡∏≤‡∏ô‡∏™‡∏π‡∏á": (13.768967962029048, 100.68565663792235),
    "‡∏ß‡∏±‡∏á‡∏ó‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏á": (13.764234425711646, 100.60572336211685),
    "‡∏Ñ‡∏•‡∏≠‡∏á‡∏™‡∏≤‡∏°‡∏ß‡∏≤": (13.859902323144107, 100.70417999674628),
    "‡∏ö‡∏≤‡∏á‡∏ô‡∏≤": (13.681182642473885, 100.59210380320427),
    "‡∏ó‡∏ß‡∏µ‡∏ß‡∏±‡∏í‡∏ô‡∏≤": (13.77301485649326, 100.35310584806938),
    "‡∏ó‡∏∏‡πà‡∏á‡∏Ñ‡∏£‡∏∏": (13.61136886293151, 100.50876871494297),
    "‡∏ö‡∏≤‡∏á‡∏ö‡∏≠‡∏ô": (13.63394263372994, 100.3689626684714)
}

model = xgb.Booster()
model.load_model(model_path)

def convert_thai_datetime(thai_str):
    # Clean and normalize
    thai_str = re.sub(r'‡∏ô\.?|‡∏ô', '', thai_str).strip()
    parts = thai_str.split()

    if len(parts) != 4:
        raise ValueError(f"Unexpected datetime format: {thai_str}")

    day = int(parts[0])
    month_thai = parts[1]
    year_be = int(parts[2])
    time_part = parts[3]

    month_map = {
        '‡∏°.‡∏Ñ.': 1, '‡∏Å.‡∏û.': 2, '‡∏°‡∏µ.‡∏Ñ.': 3, '‡πÄ‡∏°.‡∏¢.': 4,
        '‡∏û.‡∏Ñ.': 5, '‡∏°‡∏¥.‡∏¢.': 6, '‡∏Å.‡∏Ñ.': 7, '‡∏™.‡∏Ñ.': 8,
        '‡∏Å.‡∏¢.': 9, '‡∏ï.‡∏Ñ.': 10, '‡∏û.‡∏¢.': 11, '‡∏ò.‡∏Ñ.': 12
    }

    month = month_map.get(month_thai)
    if not month:
        raise ValueError(f"Unknown Thai month: {month_thai}")

    year_ad = year_be + 2500 - 543 if year_be < 100 else year_be - 543

    dt_str = f"{year_ad}-{month:02d}-{day:02d} {time_part}"
    dt = datetime.strptime(dt_str, "%Y-%m-%d %H:%M")

    # Return string without timezone (naive datetime)
    #return dt.strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]  # keep microseconds if needed
    # print(dt_str+':09.453003+00')
    return dt_str+':09.453003+00'

def get_office_location(district):
    return district_office_location[district]

def haversine(coord1, coord2):
    R = 6371.0
    lat1, lon1 = coord1
    lat2, lon2 = coord2
    phi1, phi2 = math.radians(lat1), math.radians(lat2)
    dphi = math.radians(lat2 - lat1)
    dlambda = math.radians(lon2 - lon1)
    a = math.sin(dphi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(dlambda / 2) ** 2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    return R * c

def distFromDistOff(office_coords, coords):
    coor = coords.split(",")
    return haversine((float(coor[1]), float(coor[0])), office_coords) 


# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (representative hours) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™
# class 1 (<1 ‡∏ß‡∏±‡∏ô): 12h, class 2 (1-3 ‡∏ß‡∏±‡∏ô): 48h, class 3 (3-7 ‡∏ß‡∏±‡∏ô): 120h,
# class 4 (7-21 ‡∏ß‡∏±‡∏ô): 336h, class 5 (21-90 ‡∏ß‡∏±‡∏ô): 1332h, class 6 (>90 ‡∏ß‡∏±‡∏ô): 2880h
class_hours = np.array([12, 48, 120, 336, 1332, 2880])

def predict_time(model, problem_types, timestamp, coords, district, subdistrict):
    """
    ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß

    Parameters:
        model: ‡πÇ‡∏°‡πÄ‡∏î‡∏• XGBoost trained
        problem_types: list ‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤
        timestamp: single datetime string ‡∏´‡∏£‡∏∑‡∏≠ pd.Timestamp
        coords: tuple (lat, lon)
        district: string ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡∏ï
        subdistrict: string ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏Ç‡∏ß‡∏á

    Returns:
        preds: numpy array shape (1, n_classes)
        margins: numpy array shape (1, n_classes)
        estimated_time: float ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á (weighted sum)
        total_conf: float ‡∏Ñ‡πà‡∏≤ confidence ‡∏£‡∏ß‡∏°
        details: dict (reserved for SHAP ‡∏´‡∏£‡∏∑‡∏≠ feature importance)
    """
    # ‡πÅ‡∏õ‡∏•‡∏á input ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö list/Series
    ts = pd.to_datetime([timestamp])

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame
    df = pd.DataFrame({
        'hour_of_day': ts.hour,
        'unix_time': ts.astype(int) // 10**9,
    })

    # ‡∏£‡∏∞‡∏¢‡∏∞‡∏à‡∏≤‡∏Å‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô
    office_coords = get_office_location(district)
    df['dist_from_office'] = distFromDistOff(office_coords, coords)

    # one-hot ‡πÄ‡∏Ç‡∏ï‡πÅ‡∏•‡∏∞‡πÅ‡∏Ç‡∏ß‡∏á
    df = df.assign(district=[district], subdistrict=[subdistrict])
    df = pd.get_dummies(df, columns=['district','subdistrict'], prefix=['district','subdistrict'], prefix_sep='__', dtype=int)

    # one-hot ‡∏õ‡∏±‡∏ç‡∏´‡∏≤
    mlb = MultiLabelBinarizer()
    type_df = pd.DataFrame(mlb.fit_transform([problem_types]), columns=[f"type_{c}" for c in mlb.classes_])
    df = pd.concat([df, type_df], axis=1)

    # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î
    df = df.reindex(columns=model.feature_names, fill_value=0)

    # Predict
    dmat = xgb.DMatrix(df, feature_names=model.feature_names)
    preds = model.predict(dmat)[0]
    margins = model.predict(dmat, output_margin=True)[0]

    # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°
    estimated_time = float((preds * class_hours).sum()) % 24
    total_conf = float(margins.mean())

    # ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î (placeholder)
    details = {}

    return preds, margins, estimated_time, total_conf, details



def reset_csv():
    open(stream_csv_path, 'w').close()
    print(f"üßπ Cleared file")

def infer_latest_reports():
    if not os.path.exists(stream_csv_path):
        print("‚ö†Ô∏è No CSV found to process.")
        return

    raw_df = pd.read_csv(stream_csv_path)
    if raw_df.empty:
        print("‚ö†Ô∏è No data found in CSV.")
        return

    raw_df = raw_df.sort_values("report_time", ascending=False).head(6)
    enriched = []

    for _, report in raw_df.iterrows():
        try:
            tags = report["tags"].split(",") if isinstance(report["tags"], str) else []
            time_str = convert_thai_datetime(report["report_time"])
            report["report_time"] = time_str
            location = f"{report['latitude']},{report['longitude']}"
            preds, margins, est, conf, _ = predict_time(
                model, tags, time_str, location, report["district"], report["subdistrict"]
            )
            report["est"] = est
            report["conf"] = conf
        except Exception as e:
            print(f"‚ö†Ô∏è Prediction failed for ticket_id {report.get('ticket_id', 'unknown')}: {e}")
            report["est"] = None
            report["conf"] = None

        enriched.append(report)

    pd.DataFrame(enriched).to_csv(output_csv_path, index=False, encoding='utf-8-sig')
    print(f"‚úÖ Saved top 6 predictions to {output_csv_path}")

# ---------------- DAG DEFINITIONS ----------------
def create_hourly_reset_dag():
    dag = DAG(
        dag_id="reset_traffy_csv_hourly",
        start_date=datetime(2025, 5, 6),
        schedule_interval="@hourly",
        catchup=False
    )
    PythonOperator(
        task_id="clear_raw_csv",
        python_callable=reset_csv,
        dag=dag
    )
    return dag

def create_minutely_infer_dag():
    dag = DAG(
        dag_id="infer_top6_minutely",
        start_date=datetime(2025, 5, 6),
        schedule_interval="* * * * *",
        catchup=False
    )
    PythonOperator(
        task_id="predict_top6_latest_reports",
        python_callable=infer_latest_reports,
        dag=dag
    )
    return dag

reset_dag = create_hourly_reset_dag()
infer_dag = create_minutely_infer_dag()